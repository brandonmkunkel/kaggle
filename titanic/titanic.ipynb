{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the training + validation sets\n",
    "test_csv = pd.read_csv(\"test.csv\")\n",
    "train_csv = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452723</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.215997</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.216412</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.815377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.232188</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.222638</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287881</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>0.228361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212559</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505473</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472713</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276564</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex       Age  SibSp     Parch      Fare     Cabin  Embarked\n",
       "0       1.0  0.0  0.452723  0.000  0.000000  0.015282  0.215997       1.0\n",
       "1       1.0  1.0  0.617566  0.125  0.000000  0.013663  0.216412       0.0\n",
       "2       0.5  0.0  0.815377  0.000  0.000000  0.018909  0.232188       1.0\n",
       "3       1.0  0.0  0.353818  0.000  0.000000  0.016908  0.222638       0.0\n",
       "4       1.0  1.0  0.287881  0.125  0.111111  0.023984  0.228361       0.0\n",
       "..      ...  ...       ...    ...       ...       ...       ...       ...\n",
       "413     1.0  0.0  0.422500  0.000  0.000000  0.015713  0.500000       0.0\n",
       "414     0.0  1.0  0.512066  0.000  0.000000  0.212559  0.333333       0.5\n",
       "415     1.0  0.0  0.505473  0.000  0.000000  0.014151  0.500000       0.0\n",
       "416     1.0  0.0  0.472713  0.000  0.000000  0.015713  0.500000       0.0\n",
       "417     1.0  0.0  0.276564  0.125  0.111111  0.043640  0.500000       0.5\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import impute\n",
    "\n",
    "def preprocess_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    processed = data.copy(deep=True)\n",
    "\n",
    "    # Drop columns that have no correlation\n",
    "    processed.drop([\"Ticket\", \"Name\"], axis=1, inplace=True)\n",
    "\n",
    "    # Convert gender\n",
    "    processed.replace(to_replace={\"Sex\": \"male\"}, value=0.0, inplace=True)\n",
    "    processed.replace(to_replace={\"Sex\": \"female\"}, value=1.0, inplace=True)\n",
    "\n",
    "    # Invert the classes\n",
    "    processed.replace(to_replace={\"Pclass\": \"1\"}, value=2, inplace=True)\n",
    "    processed.replace(to_replace={\"Pclass\": \"2\"}, value=1, inplace=True)\n",
    "    processed.replace(to_replace={\"Pclass\": \"3\"}, value=0, inplace=True)\n",
    "\n",
    "    # Convert cabin number to an integer\n",
    "    def normalize_cabin(letter):\n",
    "        if isinstance(letter, int) or isinstance(letter, float):\n",
    "            return letter\n",
    "        \n",
    "        letter_map = {\n",
    "            \"A\": 1000,\n",
    "            \"B\": 2000,\n",
    "            \"C\": 3000,\n",
    "            \"D\": 4000, \n",
    "            \"E\": 5000,\n",
    "            \"F\": 6000,\n",
    "            \"G\": 7000,\n",
    "        }\n",
    "        split_letter = letter.split(\" \")[0]\n",
    "        cabin = int(letter_map.get(split_letter[0].upper(), 0))\n",
    "        # room = int(split_letter[1:]) if split_letter[1:] else 0\n",
    "        room = 0\n",
    "        \n",
    "        # Convert cabin number to an int and then normalize\n",
    "        return cabin + room\n",
    "\n",
    "    processed[\"Cabin\"] = pd.Series([normalize_cabin(c) for c in processed[\"Cabin\"]])\n",
    "\n",
    "    # Convert Cabin\n",
    "    processed.replace(to_replace={\"Embarked\": \"S\"}, value=1, inplace=True)\n",
    "    processed.replace(to_replace={\"Embarked\": \"C\"}, value=2, inplace=True)\n",
    "    processed.replace(to_replace={\"Embarked\": \"Q\"}, value=3, inplace=True)\n",
    "\n",
    "    # Fill in all NaN with -1\n",
    "    # processed.fillna(-1, inplace=True)\n",
    "\n",
    "    # Impute missing values + Scale the data\n",
    "    imputer = impute.KNNImputer(n_neighbors=2, weights=\"distance\")\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    normalized_data = scaler.fit_transform(imputer.fit_transform(processed.to_numpy()))\n",
    "    scaled_processed = pd.DataFrame(normalized_data, columns=processed.columns)\n",
    "    scaled_processed[\"PassengerId\"] = processed[\"PassengerId\"]\n",
    "\n",
    "    return scaled_processed\n",
    "\n",
    "# Process the data\n",
    "train_data = preprocess_data(train_csv)\n",
    "test_data = preprocess_data(test_csv)\n",
    "\n",
    "# Split the data into inputs/output\n",
    "# Available Features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "categorical_features = [True, True, False, False, False, False, False, True]\n",
    "\n",
    "train_xdata = train_data[features]\n",
    "train_ydata = train_data[\"Survived\"]\n",
    "\n",
    "test_xdata = test_data[features]\n",
    "test_xdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingClassifier\n",
      "\tTraining Accuracy: 0.9815059445178336\n",
      "\tValidation Accuracy: 0.8582089552238806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.svm import *\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import *\n",
    "\n",
    "def save_predictions(passenger_ids, survived, filename):\n",
    "    \"\"\"\n",
    "    Save the passenger_ids and survival predictions to the given \n",
    "    \"\"\"\n",
    "    pd.DataFrame({\"PassengerId\": passenger_ids, \"Survived\": survived}).to_csv(f\"solutions/{filename}\", index=False)\n",
    "\n",
    "def run_evaluation(model_type, x, y, test_x):\n",
    "    \"\"\"\n",
    "    Evaluate a model type against\n",
    "    \"\"\"\n",
    "    # Create 20% training/validation split\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, random_state=0)\n",
    "\n",
    "    model = model_type.fit(x_train, y_train)\n",
    "    model_name = type(model).__name__\n",
    "\n",
    "    # Check validation accuracy on split training data\n",
    "    y_training = model.predict(x_train).astype(np.int32)\n",
    "    y_predictions = model.predict(x_val).astype(np.int32)\n",
    "    training_accuracy = metrics.accuracy_score(y_train.to_numpy(), y_training)\n",
    "    validation_accuracy = metrics.accuracy_score(y_val.to_numpy(), y_predictions)\n",
    "    print(f\"{model_name}\\n\\tTraining Accuracy: {training_accuracy}\\n\\tValidation Accuracy: {validation_accuracy}\")\n",
    "\n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"model\": model,\n",
    "        \"training_accuracy\": training_accuracy,\n",
    "        \"validation_accuracy\": validation_accuracy,\n",
    "        \"predictions\": model.predict(test_x)\n",
    "    }\n",
    "\n",
    "\n",
    "# params = { 'max_depth': [3, 6, 10],\n",
    "#            'learning_rate': [0.01, 0.05, 0.],\n",
    "#            'n_estimators': [10, 20, 50],\n",
    "#         #    'colsample_bytree': [0.3, 0.7],\n",
    "#            'reg_alpha': [0, 1E-5],\n",
    "#            'reg_lambda': [0, 1E-5],\n",
    "#            }\n",
    "\n",
    "# estimator = XGBClassifier(objective=\"multi:softmax\", num_class=2, colsample_bytree=0.7)\n",
    "# model = GridSearchCV(estimator=estimator, \n",
    "#                    param_grid=params,\n",
    "#                    scoring='neg_mean_squared_error', \n",
    "#                    verbose=1)\n",
    "\n",
    "# Instead of Grid Search - just select a model and manually tune parameters\n",
    "# model = XGBClassifier(\n",
    "#     objective=\"binary:logistic\",\n",
    "#     n_estimators=30,\n",
    "#     learning_rate=0.1,\n",
    "#     max_depth=10,\n",
    "#     reg_alpha=1E-5,\n",
    "#     reg_lambda=1E-5,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8,\n",
    "#     gamma = 0.0,\n",
    "#     scale_pos_weight = 1,\n",
    "#     min_child_weight = 1,\n",
    "# )\n",
    "\n",
    "model = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.15,\n",
    "    # categorical_features=categorical_features,\n",
    "    # max_bins=32, \n",
    "    max_depth=5,\n",
    "    max_iter=200, \n",
    "    l2_regularization=1E-3,\n",
    ")\n",
    "\n",
    "results = run_evaluation(model, train_xdata, train_ydata, test_xdata)\n",
    "\n",
    "# Run the model on the Kaggle Test data\n",
    "save_predictions(test_data[\"PassengerId\"], results[\"predictions\"], f\"{results['model_name']}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34336caf234ac39ff53416191c5f5aff384c3b6b599b046925061e5fc3c37047"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
