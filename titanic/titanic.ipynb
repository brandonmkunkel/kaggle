{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the training + validation sets\n",
    "test_csv = pd.read_csv(\"test.csv\")\n",
    "train_csv = pd.read_csv(\"train.csv\")\n",
    "\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      PassengerId  Survived  Pclass  Sex     Age  SibSp     Parch      Fare  \\\n",
      "0       0.000000       0.0     1.0  1.0  0.2750  0.125  0.000000  0.014151   \n",
      "1       0.001124       1.0     0.0  0.0  0.4750  0.125  0.000000  0.139136   \n",
      "2       0.002247       1.0     1.0  0.0  0.3250  0.000  0.000000  0.015469   \n",
      "3       0.003371       1.0     0.0  0.0  0.4375  0.125  0.000000  0.103644   \n",
      "4       0.004494       0.0     1.0  1.0  0.4375  0.000  0.000000  0.015713   \n",
      "..           ...       ...     ...  ...     ...    ...       ...       ...   \n",
      "886     0.995506       0.0     0.5  1.0  0.3375  0.000  0.000000  0.025374   \n",
      "887     0.996629       1.0     0.0  0.0  0.2375  0.000  0.000000  0.058556   \n",
      "888     0.997753       0.0     1.0  0.0  0.0000  0.125  0.333333  0.045771   \n",
      "889     0.998876       1.0     0.0  1.0  0.3250  0.000  0.000000  0.058556   \n",
      "890     1.000000       0.0     1.0  1.0  0.4000  0.000  0.000000  0.015127   \n",
      "\n",
      "        Cabin  Embarked  \n",
      "0    0.000000       0.0  \n",
      "1    0.440337       0.5  \n",
      "2    0.000000       0.0  \n",
      "3    0.445761       0.0  \n",
      "4    0.000000       0.0  \n",
      "..        ...       ...  \n",
      "886  0.000000       0.0  \n",
      "887  0.291464       0.0  \n",
      "888  0.000000       0.0  \n",
      "889  0.449329       0.5  \n",
      "890  0.000000       1.0  \n",
      "\n",
      "[891 rows x 10 columns]>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preprocess_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    processed = data.copy(deep=True)\n",
    "\n",
    "    # Drop columns that have no correlation\n",
    "    processed.drop([\"Ticket\", \"Name\"], axis=1, inplace=True)\n",
    "\n",
    "    # Convert gender\n",
    "    processed.replace(to_replace={\"Sex\": \"male\"}, value=1.0, inplace=True)\n",
    "    processed.replace(to_replace={\"Sex\": \"female\"}, value=0.0, inplace=True)\n",
    "\n",
    "    # Convert cabin number to an integer\n",
    "    def normalize_cabin(letter):\n",
    "        if isinstance(letter, int):\n",
    "            return letter\n",
    "        \n",
    "        letter_map = {\n",
    "            \"A\": 1000,\n",
    "            \"B\": 2000,\n",
    "            \"C\": 3000,\n",
    "            \"D\": 4000, \n",
    "            \"E\": 5000,\n",
    "            \"F\": 6000,\n",
    "            \"G\": 7000,\n",
    "        }\n",
    "        split_letter = letter.split(\" \")[0]\n",
    "        cabin = int(letter_map.get(split_letter[0].upper(), 0))\n",
    "        room = int(split_letter[1:]) if split_letter[1:] else 0\n",
    "        \n",
    "        # Convert cabin number to an int and then normalize\n",
    "        return (cabin + room) / 8000.0\n",
    "\n",
    "    processed[\"Cabin\"].fillna(0, inplace=True)\n",
    "    processed[\"Cabin\"] = pd.Series([normalize_cabin(c) for c in processed[\"Cabin\"]])\n",
    "\n",
    "    # Convert Cabin\n",
    "    processed.replace(to_replace={\"Embarked\": \"S\"}, value=0.0, inplace=True)\n",
    "    processed.replace(to_replace={\"Embarked\": \"C\"}, value=0.5, inplace=True)\n",
    "    processed.replace(to_replace={\"Embarked\": \"Q\"}, value=1.0, inplace=True)\n",
    "\n",
    "    # Fill in ages\n",
    "    # processed[\"Age\"].fillna(-1, inplace=True)\n",
    "\n",
    "    # Fill in all NaN with 0\n",
    "    processed.fillna(0, inplace=True)\n",
    "\n",
    "    # Scale the data \n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    # for column_name, column_data in processed.items():\n",
    "    #     processed[column_name] = scaler.fit_transform(column_data.values)\n",
    "\n",
    "    normalized_data = scaler.fit_transform(processed.to_numpy())\n",
    "    processed = pd.DataFrame(normalized_data, columns=processed.columns)\n",
    "\n",
    "    return processed\n",
    "\n",
    "# Process the data\n",
    "train_data = preprocess_data(train_csv)\n",
    "test_data = preprocess_data(test_csv)\n",
    "print(train_data.head)\n",
    "\n",
    "# Split the data into inputs/output\n",
    "# Available Features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", \"Embarked\"]\n",
    "\n",
    "train_xdata = train_data[features]\n",
    "train_ydata = train_data[\"Survived\"]\n",
    "\n",
    "test_xdata = test_data[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier\n",
      "\tTraining Accuracy: 0.9101123595505618\n",
      "\tValidation Accuracy: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "def save_predictions(passenger_ids, survived, filepath):\n",
    "    \"\"\"\n",
    "    Save the passenger_ids and survival predictions to the given \n",
    "    \"\"\"\n",
    "    pd.DataFrame({\"PassengerId\": passenger_ids, \"Survived\": survived}).to_csv(filepath, index=False)\n",
    "\n",
    "def calculate_accuracy(y_test: pd.Series, y_pred) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the accuracy for an output set and \n",
    "    \"\"\"\n",
    "    assert y_test.size == y_pred.size\n",
    "    accuracy = 1 - np.sum(y_test.to_numpy()  != y_pred) / y_pred.size\n",
    "    return accuracy\n",
    "\n",
    "def run_evaluation(model_type, x, y, test_x):\n",
    "    \"\"\"\n",
    "    Evaluate a model type against\n",
    "    \"\"\"\n",
    "    # Create 20% training/validation split\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    model = model_type.fit(x_train, y_train)\n",
    "    model_name = type(model).__name__\n",
    "\n",
    "    # Check validation accuracy on split training data\n",
    "    y_training = model.predict(x_train)\n",
    "    y_predictions = model.predict(x_val)\n",
    "    training_accuracy = calculate_accuracy(y_train, y_training)\n",
    "    validation_accuracy = calculate_accuracy(y_val, y_predictions)\n",
    "    print(f\"{model_name}\\n\\tTraining Accuracy: {training_accuracy}\\n\\tValidation Accuracy: {validation_accuracy}\")\n",
    "\n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"model\": model,\n",
    "        \"training_accuracy\": training_accuracy,\n",
    "        \"validation_accuracy\": validation_accuracy,\n",
    "        \"predictions\": model.predict(test_x)\n",
    "    }\n",
    "\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.svm import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import *\n",
    "\n",
    "# Create ensemble model\n",
    "# model = XGBClassifier(\n",
    "#     n_estimators=300,\n",
    "#     objective=\"binary:logistic\",\n",
    "#     max_depth=20,\n",
    "#     # warm_start=True\n",
    "# )\n",
    "# model = GradientBoostingClassifier(n_estimators = 1000,\n",
    "#                         learning_rate = 0.1,\n",
    "#                         loss = 'exponential')\n",
    "\n",
    "# model = SVC()\n",
    "\n",
    "# NN Model\n",
    "model = MLPClassifier(\n",
    "    solver=\"lbfgs\", \n",
    "    activation=\"relu\",\n",
    "    learning_rate=\"adaptive\", \n",
    "    alpha=1e-5, \n",
    "    hidden_layer_sizes=(20, 20, 20), \n",
    "    max_iter=20000, \n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "results = run_evaluation(model, train_xdata, train_ydata, test_xdata)\n",
    "\n",
    "# Run the model on the Kaggle Test data\n",
    "save_predictions(test_data[\"PassengerId\"], results[\"predictions\"], \"xgboost.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34336caf234ac39ff53416191c5f5aff384c3b6b599b046925061e5fc3c37047"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
